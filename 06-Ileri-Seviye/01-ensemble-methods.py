"""
Ensemble YÃ¶ntemleri ve Ä°leri Seviye Makine Ã–ÄŸrenmesi
OpenCV ile Ensemble Learning UygulamalarÄ±

Bu dosya, ensemble yÃ¶ntemlerini ve ileri seviye makine Ã¶ÄŸrenmesi 
tekniklerini OpenCV kullanarak uygular.

Yazar: OpenCV TÃ¼rkiye TopluluÄŸu
Tarih: 2025
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.ensemble import VotingClassifier, BaggingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import make_classification, make_regression
from sklearn.preprocessing import StandardScaler
import time
import warnings
warnings.filterwarnings('ignore')

class EnsembleLearningDemo:
    """Ensemble Learning yÃ¶ntemlerini gÃ¶steren demo sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        """Ensemble learning demo sÄ±nÄ±fÄ±nÄ± baÅŸlat"""
        self.models = {}
        self.scaler = StandardScaler()
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
    def veri_hazirla(self, n_samples=1000, n_features=20, n_classes=3):
        """Ensemble learning iÃ§in veri seti hazÄ±rla"""
        print("ğŸ“Š Ensemble Learning iÃ§in veri hazÄ±rlanÄ±yor...")
        
        # KarmaÅŸÄ±k veri seti oluÅŸtur
        X, y = make_classification(
            n_samples=n_samples,
            n_features=n_features,
            n_informative=15,
            n_redundant=3,
            n_repeated=2,
            n_classes=n_classes,
            n_clusters_per_class=1,
            random_state=42
        )
        
        # Veriyi bÃ¶l
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        
        # Ã–zellikleri normalize et
        self.X_train = self.scaler.fit_transform(self.X_train)
        self.X_test = self.scaler.transform(self.X_test)
        
        print(f"âœ… Veri hazÄ±rlandÄ±: {self.X_train.shape[0]} eÄŸitim, {self.X_test.shape[0]} test Ã¶rneÄŸi")
        print(f"ğŸ“ˆ Ã–zellik sayÄ±sÄ±: {self.X_train.shape[1]}, SÄ±nÄ±f sayÄ±sÄ±: {len(np.unique(y))}")
        
    def bagging_ornegi(self):
        """Bagging (Bootstrap Aggregating) Ã¶rneÄŸi"""
        print("\nğŸ‘œ BAGGING (Bootstrap Aggregating) Ã–rneÄŸi")
        print("=" * 50)
        
        # Bagging Classifier
        bagging_clf = BaggingClassifier(
            base_estimator=RandomForestClassifier(n_estimators=10, random_state=42),
            n_estimators=5,
            max_samples=0.8,
            bootstrap=True,
            random_state=42
        )
        
        # Modeli eÄŸit
        start_time = time.time()
        bagging_clf.fit(self.X_train, self.y_train)
        training_time = time.time() - start_time
        
        # Tahmin yap
        y_pred = bagging_clf.predict(self.X_test)
        accuracy = accuracy_score(self.y_test, y_pred)
        
        print(f"â±ï¸  EÄŸitim sÃ¼resi: {training_time:.3f} saniye")
        print(f"ğŸ¯ DoÄŸruluk: {accuracy:.4f}")
        print(f"ğŸ“Š SÄ±nÄ±flandÄ±rma Raporu:")
        print(classification_report(self.y_test, y_pred))
        
        self.models['bagging'] = bagging_clf
        return bagging_clf
        
    def boosting_ornegi(self):
        """Boosting Ã¶rneÄŸi (AdaBoost ve Gradient Boosting)"""
        print("\nğŸš€ BOOSTING Ã–rneÄŸi")
        print("=" * 50)
        
        # AdaBoost
        print("ğŸ“ˆ AdaBoost Classifier:")
        adaboost_clf = AdaBoostClassifier(
            n_estimators=50,
            learning_rate=1.0,
            random_state=42
        )
        
        start_time = time.time()
        adaboost_clf.fit(self.X_train, self.y_train)
        adaboost_time = time.time() - start_time
        
        y_pred_adaboost = adaboost_clf.predict(self.X_test)
        accuracy_adaboost = accuracy_score(self.y_test, y_pred_adaboost)
        
        print(f"â±ï¸  EÄŸitim sÃ¼resi: {adaboost_time:.3f} saniye")
        print(f"ğŸ¯ DoÄŸruluk: {accuracy_adaboost:.4f}")
        
        # Gradient Boosting
        print("\nğŸ“ˆ Gradient Boosting Classifier:")
        gb_clf = GradientBoostingClassifier(
            n_estimators=50,
            learning_rate=0.1,
            max_depth=3,
            random_state=42
        )
        
        start_time = time.time()
        gb_clf.fit(self.X_train, self.y_train)
        gb_time = time.time() - start_time
        
        y_pred_gb = gb_clf.predict(self.X_test)
        accuracy_gb = accuracy_score(self.y_test, y_pred_gb)
        
        print(f"â±ï¸  EÄŸitim sÃ¼resi: {gb_time:.3f} saniye")
        print(f"ğŸ¯ DoÄŸruluk: {accuracy_gb:.4f}")
        
        self.models['adaboost'] = adaboost_clf
        self.models['gradient_boosting'] = gb_clf
        
        return adaboost_clf, gb_clf
        
    def voting_ornegi(self):
        """Voting (Oylama) ensemble Ã¶rneÄŸi"""
        print("\nğŸ—³ï¸ VOTING ENSEMBLE Ã–rneÄŸi")
        print("=" * 50)
        
        # FarklÄ± base classifier'lar
        from sklearn.svm import SVC
        from sklearn.linear_model import LogisticRegression
        
        clf1 = RandomForestClassifier(n_estimators=50, random_state=42)
        clf2 = SVC(probability=True, random_state=42)
        clf3 = LogisticRegression(random_state=42)
        
        # Voting Classifier (Soft Voting)
        voting_clf = VotingClassifier(
            estimators=[
                ('rf', clf1),
                ('svc', clf2),
                ('lr', clf3)
            ],
            voting='soft'  # Soft voting (probability-based)
        )
        
        # Modeli eÄŸit
        start_time = time.time()
        voting_clf.fit(self.X_train, self.y_train)
        training_time = time.time() - start_time
        
        # Tahmin yap
        y_pred = voting_clf.predict(self.X_test)
        accuracy = accuracy_score(self.y_test, y_pred)
        
        print(f"â±ï¸  EÄŸitim sÃ¼resi: {training_time:.3f} saniye")
        print(f"ğŸ¯ DoÄŸruluk: {accuracy:.4f}")
        print(f"ğŸ“Š SÄ±nÄ±flandÄ±rma Raporu:")
        print(classification_report(self.y_test, y_pred))
        
        self.models['voting'] = voting_clf
        return voting_clf
        
    def cross_validation_karsilastirma(self):
        """FarklÄ± ensemble yÃ¶ntemlerini cross-validation ile karÅŸÄ±laÅŸtÄ±r"""
        print("\nğŸ”„ CROSS-VALIDATION KARÅILAÅTIRMASI")
        print("=" * 50)
        
        models = {
            'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42),
            'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, random_state=42),
            'Bagging': BaggingClassifier(n_estimators=5, random_state=42),
            'Voting': VotingClassifier(
                estimators=[
                    ('rf', RandomForestClassifier(n_estimators=20, random_state=42)),
                    ('gb', GradientBoostingClassifier(n_estimators=20, random_state=42))
                ],
                voting='soft'
            )
        }
        
        results = {}
        for name, model in models.items():
            scores = cross_val_score(model, self.X_train, self.y_train, cv=5)
            results[name] = {
                'mean': scores.mean(),
                'std': scores.std(),
                'scores': scores
            }
            print(f"{name:20} | Ortalama: {scores.mean():.4f} | Std: {scores.std():.4f}")
            
        return results
        
    def performans_analizi(self):
        """Ensemble modellerin performans analizi"""
        print("\nğŸ“Š PERFORMANS ANALÄ°ZÄ°")
        print("=" * 50)
        
        if not self.models:
            print("âŒ Ã–nce modelleri eÄŸitin!")
            return
            
        results = {}
        for name, model in self.models.items():
            # Test doÄŸruluÄŸu
            y_pred = model.predict(self.X_test)
            accuracy = accuracy_score(self.y_test, y_pred)
            
            # Cross-validation
            cv_scores = cross_val_score(model, self.X_train, self.y_train, cv=5)
            
            results[name] = {
                'test_accuracy': accuracy,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std()
            }
            
            print(f"\n{name.upper()}:")
            print(f"  ğŸ¯ Test DoÄŸruluÄŸu: {accuracy:.4f}")
            print(f"  ğŸ“ˆ CV Ortalama: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
            
        return results
        
    def ensemble_gorselleÅŸtirme(self):
        """Ensemble yÃ¶ntemlerin gÃ¶rselleÅŸtirilmesi"""
        print("\nğŸ¨ ENSEMBLE GÃ–RSELLEÅTÄ°RME")
        print("=" * 50)
        
        # Basit 2D veri seti oluÅŸtur
        X_simple, y_simple = make_classification(
            n_samples=300,
            n_features=2,
            n_informative=2,
            n_redundant=0,
            n_classes=2,
            random_state=42
        )
        
        X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(
            X_simple, y_simple, test_size=0.3, random_state=42
        )
        
        # FarklÄ± ensemble modeller
        models = {
            'Random Forest': RandomForestClassifier(n_estimators=10, random_state=42),
            'AdaBoost': AdaBoostClassifier(n_estimators=10, random_state=42),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=10, random_state=42)
        }
        
        # GÃ¶rselleÅŸtirme
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        fig.suptitle('Ensemble YÃ¶ntemlerin KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=16)
        
        for idx, (name, model) in enumerate(models.items()):
            # Modeli eÄŸit
            model.fit(X_train_simple, y_train_simple)
            
            # Karar sÄ±nÄ±rlarÄ±nÄ± Ã§iz
            x_min, x_max = X_simple[:, 0].min() - 1, X_simple[:, 0].max() + 1
            y_min, y_max = X_simple[:, 1].min() - 1, X_simple[:, 1].max() + 1
            xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                                np.arange(y_min, y_max, 0.1))
            
            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
            Z = Z.reshape(xx.shape)
            
            # Plot
            axes[idx].contourf(xx, yy, Z, alpha=0.4)
            axes[idx].scatter(X_train_simple[:, 0], X_train_simple[:, 1], 
                            c=y_train_simple, alpha=0.8, edgecolors='black')
            axes[idx].set_title(f'{name}\nDoÄŸruluk: {accuracy_score(y_test_simple, model.predict(X_test_simple)):.3f}')
            axes[idx].set_xlabel('Ã–zellik 1')
            axes[idx].set_ylabel('Ã–zellik 2')
            
        plt.tight_layout()
        plt.show()
        
    def gercek_dunya_ornegi(self):
        """GerÃ§ek dÃ¼nya ensemble learning Ã¶rneÄŸi"""
        print("\nğŸŒ GERÃ‡EK DÃœNYA Ã–RNEÄÄ°: Ã‡oklu SensÃ¶r Verisi SÄ±nÄ±flandÄ±rmasÄ±")
        print("=" * 70)
        
        # SimÃ¼le edilmiÅŸ sensÃ¶r verisi
        np.random.seed(42)
        n_samples = 1000
        
        # FarklÄ± sensÃ¶rlerden gelen veriler
        sensor1 = np.random.normal(0, 1, n_samples)  # SÄ±caklÄ±k sensÃ¶rÃ¼
        sensor2 = np.random.normal(0, 1, n_samples)  # Nem sensÃ¶rÃ¼
        sensor3 = np.random.normal(0, 1, n_samples)  # BasÄ±nÃ§ sensÃ¶rÃ¼
        sensor4 = np.random.normal(0, 1, n_samples)  # IÅŸÄ±k sensÃ¶rÃ¼
        
        # GÃ¼rÃ¼ltÃ¼ ekle
        noise = np.random.normal(0, 0.1, n_samples)
        
        # Hedef deÄŸiÅŸken (anomali tespiti)
        # KarmaÅŸÄ±k bir kural oluÅŸtur
        target = ((sensor1 > 1.5) & (sensor2 < -0.5)) | \
                 ((sensor3 > 1.0) & (sensor4 < -1.0)) | \
                 ((sensor1 + sensor2 + sensor3 + sensor4) > 3.0)
        
        target = target.astype(int)
        
        # Veriyi birleÅŸtir
        X_sensor = np.column_stack([sensor1, sensor2, sensor3, sensor4])
        X_sensor += noise.reshape(-1, 1)
        
        # Veriyi bÃ¶l
        X_train_sensor, X_test_sensor, y_train_sensor, y_test_sensor = train_test_split(
            X_sensor, target, test_size=0.3, random_state=42
        )
        
        # Ensemble modeller
        ensemble_models = {
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, random_state=42),
            'Voting Ensemble': VotingClassifier(
                estimators=[
                    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),
                    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))
                ],
                voting='soft'
            )
        }
        
        print("ğŸ“Š SensÃ¶r Verisi Analizi:")
        print(f"   - Toplam Ã¶rnek: {len(X_sensor)}")
        print(f"   - Anomali oranÄ±: {np.mean(target):.2%}")
        print(f"   - SensÃ¶r sayÄ±sÄ±: {X_sensor.shape[1]}")
        
        results = {}
        for name, model in ensemble_models.items():
            # Modeli eÄŸit
            model.fit(X_train_sensor, y_train_sensor)
            
            # Tahmin yap
            y_pred = model.predict(X_test_sensor)
            accuracy = accuracy_score(y_test_sensor, y_pred)
            
            results[name] = accuracy
            print(f"\n{name}:")
            print(f"  ğŸ¯ DoÄŸruluk: {accuracy:.4f}")
            print(f"  ğŸ“Š SÄ±nÄ±flandÄ±rma Raporu:")
            print(classification_report(y_test_sensor, y_pred))
            
        return results

def demo_menu():
    """Demo menÃ¼sÃ¼"""
    demo = EnsembleLearningDemo()
    
    while True:
        print("\n" + "="*60)
        print("ğŸ¯ ENSEMBLE LEARNING DEMO MENÃœSÃœ")
        print("="*60)
        print("1. ğŸ“Š Veri HazÄ±rlama")
        print("2. ğŸ‘œ Bagging Ã–rneÄŸi")
        print("3. ğŸš€ Boosting Ã–rneÄŸi")
        print("4. ğŸ—³ï¸ Voting Ensemble Ã–rneÄŸi")
        print("5. ğŸ”„ Cross-Validation KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        print("6. ğŸ“Š Performans Analizi")
        print("7. ğŸ¨ Ensemble GÃ¶rselleÅŸtirme")
        print("8. ğŸŒ GerÃ§ek DÃ¼nya Ã–rneÄŸi")
        print("0. âŒ Ã‡Ä±kÄ±ÅŸ")
        
        try:
            secim = input("\nSeÃ§iminizi yapÄ±n (0-8): ").strip()
            
            if secim == "0":
                print("ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
                break
            elif secim == "1":
                demo.veri_hazirla()
            elif secim == "2":
                if demo.X_train is None:
                    print("âŒ Ã–nce veri hazÄ±rlayÄ±n! (SeÃ§enek 1)")
                else:
                    demo.bagging_ornegi()
            elif secim == "3":
                if demo.X_train is None:
                    print("âŒ Ã–nce veri hazÄ±rlayÄ±n! (SeÃ§enek 1)")
                else:
                    demo.boosting_ornegi()
            elif secim == "4":
                if demo.X_train is None:
                    print("âŒ Ã–nce veri hazÄ±rlayÄ±n! (SeÃ§enek 1)")
                else:
                    demo.voting_ornegi()
            elif secim == "5":
                if demo.X_train is None:
                    print("âŒ Ã–nce veri hazÄ±rlayÄ±n! (SeÃ§enek 1)")
                else:
                    demo.cross_validation_karsilastirma()
            elif secim == "6":
                if not demo.models:
                    print("âŒ Ã–nce modelleri eÄŸitin!")
                else:
                    demo.performans_analizi()
            elif secim == "7":
                demo.ensemble_gorselleÅŸtirme()
            elif secim == "8":
                demo.gercek_dunya_ornegi()
            else:
                print("âŒ GeÃ§ersiz seÃ§im! LÃ¼tfen 0-8 arasÄ±nda bir sayÄ± girin.")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Program sonlandÄ±rÄ±ldÄ±!")
            break
        except Exception as e:
            print(f"âŒ Hata oluÅŸtu: {e}")

if __name__ == "__main__":
    print("ğŸ¯ Ensemble Learning ve Ä°leri Seviye Makine Ã–ÄŸrenmesi")
    print("=" * 60)
    print("Bu demo, ensemble yÃ¶ntemlerini ve ileri seviye ML tekniklerini gÃ¶sterir.")
    print("ğŸ“š Ã–ÄŸrenilecek Konular:")
    print("  â€¢ Bagging (Bootstrap Aggregating)")
    print("  â€¢ Boosting (AdaBoost, Gradient Boosting)")
    print("  â€¢ Voting (Oylama) Ensemble")
    print("  â€¢ Cross-Validation KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    print("  â€¢ Performans Analizi")
    print("  â€¢ GerÃ§ek DÃ¼nya UygulamalarÄ±")
    
    demo_menu() 