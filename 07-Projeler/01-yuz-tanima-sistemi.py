"""
Y√ºz Tanƒ±ma ve Duygu Analizi Sistemi
OpenCV ile Y√ºz Tanƒ±ma ve Duygu Analizi Projesi

Bu proje, y√ºz tanƒ±ma ve duygu analizi tekniklerini kullanarak
ger√ßek zamanlƒ± bir sistem geli≈ütirir.

Yazar: OpenCV T√ºrkiye Topluluƒüu
Tarih: 2025
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
import pickle
import os
import time
import warnings
warnings.filterwarnings('ignore')

class YuzTanimaSistemi:
    """Y√ºz tanƒ±ma ve duygu analizi sistemi"""
    
    def __init__(self):
        """Sistem ba≈ülatma"""
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
        self.smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
        
        # Y√ºz tanƒ±ma i√ßin LBPH recognizer
        self.face_recognizer = cv2.face.LBPHFaceRecognizer_create()
        
        # Duygu analizi i√ßin model
        self.emotion_model = None
        self.emotion_labels = ['Mutlu', 'Uzgun', 'Sinirli', 'Saskin', 'Korkmus', 'Igrenmis', 'Nostral']
        
        # Kullanƒ±cƒ± veritabanƒ±
        self.users = {}
        self.current_user = None
        
    def yuz_tespit(self, frame):
        """Y√ºz tespit et"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30, 30)
        )
        return faces, gray
        
    def goz_tespit(self, frame, face_roi):
        """G√∂z tespit et"""
        x, y, w, h = face_roi
        roi_gray = frame[y:y+h, x:x+w]
        eyes = self.eye_cascade.detectMultiScale(roi_gray)
        return eyes
        
    def gulumseme_tespit(self, frame, face_roi):
        """G√ºl√ºmseme tespit et"""
        x, y, w, h = face_roi
        roi_gray = frame[y:y+h, x:x+w]
        smiles = self.smile_cascade.detectMultiScale(
            roi_gray,
            scaleFactor=1.8,
            minNeighbors=20
        )
        return smiles
        
    def yuz_ozellikleri_cikar(self, face_roi, gray):
        """Y√ºz √∂zelliklerini √ßƒ±kar"""
        x, y, w, h = face_roi
        face_roi_gray = gray[y:y+h, x:x+w]
        
        # Y√ºz √∂zellikleri
        features = []
        
        # Histogram √∂zellikleri
        hist = cv2.calcHist([face_roi_gray], [0], None, [256], [0, 256])
        hist = cv2.normalize(hist, hist).flatten()
        features.extend(hist[:50])  # ƒ∞lk 50 deƒüer
        
        # LBP √∂zellikleri (basitle≈ütirilmi≈ü)
        lbp = self.lbp_ozellikleri(face_roi_gray)
        features.extend(lbp)
        
        # Geometrik √∂zellikler
        aspect_ratio = w / h
        features.append(aspect_ratio)
        
        return np.array(features)
        
    def lbp_ozellikleri(self, img):
        """LBP (Local Binary Pattern) √∂zellikleri"""
        # Basitle≈ütirilmi≈ü LBP
        height, width = img.shape
        lbp = np.zeros((height, width), dtype=np.uint8)
        
        for i in range(1, height-1):
            for j in range(1, width-1):
                center = img[i, j]
                code = 0
                
                # 8 kom≈üu piksel
                neighbors = [
                    img[i-1, j-1], img[i-1, j], img[i-1, j+1],
                    img[i, j+1], img[i+1, j+1], img[i+1, j],
                    img[i+1, j-1], img[i, j-1]
                ]
                
                for k, neighbor in enumerate(neighbors):
                    if neighbor >= center:
                        code |= (1 << k)
                
                lbp[i, j] = code
        
        # LBP histogram
        hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0, 256))
        hist = hist.astype(np.float32)
        hist /= (hist.sum() + 1e-7)
        
        return hist[:32]  # ƒ∞lk 32 deƒüer
        
    def duygu_analizi(self, face_roi, gray):
        """Duygu analizi yap"""
        if self.emotion_model is None:
            return "Model yuklenmedi"
            
        features = self.yuz_ozellikleri_cikar(face_roi, gray)
        features = features.reshape(1, -1)
        
        try:
            prediction = self.emotion_model.predict(features)[0]
            confidence = self.emotion_model.predict_proba(features)[0].max()
            return self.emotion_labels[prediction], confidence
        except:
            return "Bilinmiyor", 0.0
            
    def yuz_tanima(self, face_roi, gray):
        """Y√ºz tanƒ±ma yap"""
        if len(self.users) == 0:
            return "Kullanici yok", 0.0
            
        x, y, w, h = face_roi
        face_roi_gray = gray[y:y+h, x:x+w]
        face_roi_gray = cv2.resize(face_roi_gray, (100, 100))
        
        try:
            label, confidence = self.face_recognizer.predict(face_roi_gray)
            if confidence < 100:  # E≈üik deƒüeri
                user_name = list(self.users.keys())[label]
                return user_name, confidence
            else:
                return "Bilinmeyen", confidence
        except:
            return "Hata", 0.0
            
    def kullanici_ekle(self, name, face_images):
        """Yeni kullanƒ±cƒ± ekle"""
        if name in self.users:
            print(f"‚ùå {name} kullanƒ±cƒ±sƒ± zaten mevcut!")
            return False
            
        # Y√ºz g√∂r√ºnt√ºlerini hazƒ±rla
        prepared_faces = []
        labels = []
        
        for i, img in enumerate(face_images):
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            gray = cv2.resize(gray, (100, 100))
            prepared_faces.append(gray)
            labels.append(len(self.users))
            
        # Kullanƒ±cƒ±yƒ± ekle
        self.users[name] = {
            'images': prepared_faces,
            'label': len(self.users)
        }
        
        # Modeli yeniden eƒüit
        self.model_egit()
        
        print(f"‚úÖ {name} kullanƒ±cƒ±sƒ± eklendi!")
        return True
        
    def model_egit(self):
        """Y√ºz tanƒ±ma modelini eƒüit"""
        if len(self.users) == 0:
            return
            
        faces = []
        labels = []
        
        for user_name, user_data in self.users.items():
            for face_img in user_data['images']:
                faces.append(face_img)
                labels.append(user_data['label'])
                
        if len(faces) > 0:
            self.face_recognizer.train(faces, np.array(labels))
            print("‚úÖ Y√ºz tanƒ±ma modeli eƒüitildi!")
            
    def duygu_modeli_egit(self, training_data):
        """Duygu analizi modelini eƒüit"""
        X = []
        y = []
        
        for emotion, features_list in training_data.items():
            for features in features_list:
                X.append(features)
                y.append(emotion)
                
        if len(X) > 0:
            # Label encoding
            le = LabelEncoder()
            y_encoded = le.fit_transform(y)
            
            # Model eƒüitimi
            self.emotion_model = RandomForestClassifier(n_estimators=100, random_state=42)
            self.emotion_model.fit(X, y_encoded)
            
            print("‚úÖ Duygu analizi modeli eƒüitildi!")
            
    def gercek_zamanli_analiz(self):
        """Ger√ßek zamanlƒ± y√ºz analizi"""
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("‚ùå Webcam a√ßƒ±lamadƒ±!")
            return
            
        print("üìπ Ger√ßek zamanlƒ± y√ºz analizi ba≈ülatƒ±ldƒ±!")
        print("üîë Kontroller:")
        print("  'q' - √áƒ±kƒ±≈ü")
        print("  's' - Ekran g√∂r√ºnt√ºs√º al")
        print("  'r' - Y√ºz tanƒ±ma modunu deƒüi≈ütir")
        
        face_recognition_mode = True
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # Y√ºz tespit
            faces, gray = self.yuz_tespit(frame)
            
            for (x, y, w, h) in faces:
                # Y√ºz √ßer√ßevesi √ßiz
                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
                
                # Y√ºz tanƒ±ma
                if face_recognition_mode and len(self.users) > 0:
                    user_name, confidence = self.yuz_tanima((x, y, w, h), gray)
                    cv2.putText(frame, f"Kullanici: {user_name}", 
                               (x, y-60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                    cv2.putText(frame, f"Guven: {confidence:.1f}", 
                               (x, y-40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                
                # Duygu analizi
                emotion, emotion_conf = self.duygu_analizi((x, y, w, h), gray)
                cv2.putText(frame, f"Duygu: {emotion}", 
                           (x, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, f"Guven: {emotion_conf:.2f}", 
                           (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # G√∂z tespit
                eyes = self.goz_tespit(gray, (x, y, w, h))
                for (ex, ey, ew, eh) in eyes:
                    cv2.rectangle(frame, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (0, 255, 0), 1)
                    
                # G√ºl√ºmseme tespit
                smiles = self.gulumseme_tespit(gray, (x, y, w, h))
                for (sx, sy, sw, sh) in smiles:
                    cv2.rectangle(frame, (x+sx, y+sy), (x+sx+sw, y+sy+sh), (0, 0, 255), 1)
                    
            # Mod bilgisi
            mode_text = "Yuz Tanima" if face_recognition_mode else "Sadece Duygu Analizi"
            cv2.putText(frame, f"Mod: {mode_text}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            cv2.imshow('Yuz Tanima ve Duygu Analizi', frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                face_recognition_mode = not face_recognition_mode
                print(f"üîÑ Mod deƒüi≈ütirildi: {mode_text}")
            elif key == ord('s'):
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"screenshot_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                print(f"üì∏ Ekran g√∂r√ºnt√ºs√º kaydedildi: {filename}")
                
        cap.release()
        cv2.destroyAllWindows()
        
    def kullanici_kayit(self):
        """Yeni kullanƒ±cƒ± kayƒ±t sistemi"""
        print("üë§ Yeni Kullanƒ±cƒ± Kayƒ±t Sistemi")
        print("=" * 50)
        
        name = input("Kullanƒ±cƒ± adƒ±nƒ± girin: ").strip()
        if not name:
            print("‚ùå Ge√ßersiz kullanƒ±cƒ± adƒ±!")
            return
            
        print(f"üì∏ {name} i√ßin y√ºz g√∂r√ºnt√ºleri alƒ±nƒ±yor...")
        print("üí° Farklƒ± a√ßƒ±lardan 5 fotoƒüraf √ßekin")
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("‚ùå Webcam a√ßƒ±lamadƒ±!")
            return
            
        face_images = []
        count = 0
        
        while count < 5:
            ret, frame = cap.read()
            if not ret:
                continue
                
            faces, gray = self.yuz_tespit(frame)
            
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
                
            cv2.putText(frame, f"Fotoƒüraf: {count+1}/5", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, "SPACE - Fotoƒüraf √ßek", 
                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, "ESC - ƒ∞ptal", 
                       (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            cv2.imshow('Kullanƒ±cƒ± Kayƒ±t', frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
            elif key == 32:  # SPACE
                if len(faces) > 0:
                    face_img = frame.copy()
                    face_images.append(face_img)
                    count += 1
                    print(f"‚úÖ Fotoƒüraf {count} alƒ±ndƒ±")
                    
        cap.release()
        cv2.destroyAllWindows()
        
        if len(face_images) == 5:
            self.kullanici_ekle(name, face_images)
        else:
            print("‚ùå Yeterli fotoƒüraf alƒ±namadƒ±!")
            
    def model_kaydet(self, filename="yuz_tanima_modeli.pkl"):
        """Modeli kaydet"""
        model_data = {
            'users': self.users,
            'face_recognizer': self.face_recognizer,
            'emotion_model': self.emotion_model
        }
        
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f)
        print(f"‚úÖ Model kaydedildi: {filename}")
        
    def model_yukle(self, filename="yuz_tanima_modeli.pkl"):
        """Modeli y√ºkle"""
        if os.path.exists(filename):
            with open(filename, 'rb') as f:
                model_data = pickle.load(f)
                
            self.users = model_data['users']
            self.face_recognizer = model_data['face_recognizer']
            self.emotion_model = model_data['emotion_model']
            print(f"‚úÖ Model y√ºklendi: {filename}")
        else:
            print(f"‚ùå Model dosyasƒ± bulunamadƒ±: {filename}")
            
    def istatistikler(self):
        """Sistem istatistikleri"""
        print("\nüìä Sƒ∞STEM ƒ∞STATƒ∞STƒ∞KLERƒ∞")
        print("=" * 50)
        print(f"üë• Kayƒ±tlƒ± kullanƒ±cƒ± sayƒ±sƒ±: {len(self.users)}")
        
        if self.users:
            print("\nüìã Kullanƒ±cƒ± listesi:")
            for i, (name, data) in enumerate(self.users.items()):
                print(f"  {i+1}. {name} ({len(data['images'])} fotoƒüraf)")
                
        if self.emotion_model:
            print(f"\nüòä Duygu analizi modeli: ‚úÖ Y√ºkl√º")
        else:
            print(f"\nüòä Duygu analizi modeli: ‚ùå Y√ºklenmedi")
            
        print(f"\nü§ñ Y√ºz tanƒ±ma modeli: ‚úÖ Hazƒ±r")

def demo_menu():
    """Demo men√ºs√º"""
    sistem = YuzTanimaSistemi()
    
    # Model y√ºklemeyi dene
    sistem.model_yukle()
    
    while True:
        print("\n" + "="*60)
        print("üë§ Y√úZ TANIMA VE DUYGU ANALƒ∞Zƒ∞ Sƒ∞STEMƒ∞")
        print("="*60)
        print("1. üë§ Yeni Kullanƒ±cƒ± Kayƒ±t")
        print("2. üìπ Ger√ßek Zamanlƒ± Analiz")
        print("3. üìä Sistem ƒ∞statistikleri")
        print("4. üíæ Model Kaydet")
        print("5. üìÇ Model Y√ºkle")
        print("6. üéØ Demo Modu")
        print("0. ‚ùå √áƒ±kƒ±≈ü")
        
        try:
            secim = input("\nSe√ßiminizi yapƒ±n (0-6): ").strip()
            
            if secim == "0":
                print("üëã G√∂r√º≈ümek √ºzere!")
                break
            elif secim == "1":
                sistem.kullanici_kayit()
            elif secim == "2":
                sistem.gercek_zamanli_analiz()
            elif secim == "3":
                sistem.istatistikler()
            elif secim == "4":
                sistem.model_kaydet()
            elif secim == "5":
                filename = input("Model dosya adƒ±nƒ± girin: ").strip()
                if filename:
                    sistem.model_yukle(filename)
                else:
                    sistem.model_yukle()
            elif secim == "6":
                print("üéØ Demo modu ba≈ülatƒ±lƒ±yor...")
                print("üí° Bu mod, √∂rnek verilerle sistemi test eder")
                
                # Demo kullanƒ±cƒ±larƒ± ekle
                if len(sistem.users) == 0:
                    print("üìù Demo kullanƒ±cƒ±larƒ± ekleniyor...")
                    # Burada demo kullanƒ±cƒ±larƒ± eklenebilir
                    
                sistem.gercek_zamanli_analiz()
            else:
                print("‚ùå Ge√ßersiz se√ßim! L√ºtfen 0-6 arasƒ±nda bir sayƒ± girin.")
                
        except KeyboardInterrupt:
            print("\nüëã Program sonlandƒ±rƒ±ldƒ±!")
            break
        except Exception as e:
            print(f"‚ùå Hata olu≈ütu: {e}")

if __name__ == "__main__":
    print("üë§ Y√ºz Tanƒ±ma ve Duygu Analizi Sistemi")
    print("=" * 60)
    print("Bu proje, y√ºz tanƒ±ma ve duygu analizi tekniklerini uygular.")
    print("üìö √ñƒürenilecek Konular:")
    print("  ‚Ä¢ Haar Cascade ile y√ºz tespiti")
    print("  ‚Ä¢ LBPH ile y√ºz tanƒ±ma")
    print("  ‚Ä¢ Duygu analizi algoritmalarƒ±")
    print("  ‚Ä¢ Ger√ßek zamanlƒ± video i≈üleme")
    print("  ‚Ä¢ Model kaydetme/y√ºkleme")
    
    demo_menu() 