#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ–¼ï¸ Frame Ä°ÅŸleme - OpenCV Video Frame ManipÃ¼lasyonu
================================================

Bu modÃ¼l video frame'lerinin iÅŸlenmesi konularÄ±nÄ± kapsar:
- Frame-by-frame video iÅŸleme
- Frame manipÃ¼lasyonu ve transformasyonlar  
- Frame buffer yÃ¶netimi
- Synchronized frame iÅŸleme
- Frame interpolation ve blending

Yazan: Eren Terzi
Tarih: 2024
"""

import cv2
import numpy as np
import os
import time
from collections import deque
from pathlib import Path
import threading
import queue

class FrameProcessor:
    """Frame iÅŸleme sÄ±nÄ±fÄ±"""
    
    def __init__(self, buffer_size=10):
        self.frame_buffer = deque(maxlen=buffer_size)
        self.processed_buffer = deque(maxlen=buffer_size)
        self.frame_count = 0
        
    def add_frame(self, frame):
        """Buffer'a frame ekle"""
        self.frame_buffer.append(frame.copy())
        self.frame_count += 1
    
    def get_current_frame(self):
        """Mevcut frame'i al"""
        return self.frame_buffer[-1] if self.frame_buffer else None
    
    def get_previous_frame(self, steps_back=1):
        """Ã–nceki frame'i al"""
        if len(self.frame_buffer) > steps_back:
            return self.frame_buffer[-(steps_back + 1)]
        return None

def ornek_1_frame_by_frame_islreme():
    """
    Ã–rnek 1: Frame-by-frame video iÅŸleme
    """
    print("\nğŸ¯ Ã–rnek 1: Frame-by-Frame Ä°ÅŸleme")
    print("=" * 40)
    
    # Test video yolu (Ã¶nceki modÃ¼lden)
    video_path = "test_video.avi"
    if not os.path.exists(video_path):
        print("âŒ Test videosu bulunamadÄ±. Ã–nce 01-video-temelleri.py Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return
    
    cap = cv2.VideoCapture(video_path)
    processor = FrameProcessor()
    
    print("ğŸ“ Ä°ÅŸleme seÃ§enekleri:")
    print("1: Orijinal")
    print("2: Gri tonlama")
    print("3: Blur")
    print("4: Kenar algÄ±lama")
    print("5: Histogram eÅŸitleme")
    print("ESC: Ã‡Ä±kÄ±ÅŸ, Space: Duraklat")
    
    processing_mode = 1
    paused = False
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                # Video sona erdi, baÅŸa dÃ¶n
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
            
            processor.add_frame(frame)
            
            # Frame iÅŸleme modlarÄ±na gÃ¶re iÅŸle
            if processing_mode == 1:
                processed_frame = frame.copy()
                mode_text = "Orijinal"
            elif processing_mode == 2:
                processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)
                mode_text = "Gri Tonlama"
            elif processing_mode == 3:
                processed_frame = cv2.GaussianBlur(frame, (15, 15), 0)
                mode_text = "Gaussian Blur"
            elif processing_mode == 4:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                edges = cv2.Canny(gray, 50, 150)
                processed_frame = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
                mode_text = "Kenar AlgÄ±lama"
            elif processing_mode == 5:
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])
                processed_frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                mode_text = "Histogram EÅŸitleme"
            
            # Bilgi metni ekle
            cv2.putText(processed_frame, f"Mod: {mode_text}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(processed_frame, f"Frame: {processor.frame_count}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            if paused:
                cv2.putText(processed_frame, "PAUSED", (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        cv2.imshow('Frame Ä°ÅŸleme', processed_frame)
        
        key = cv2.waitKey(30) & 0xFF
        if key == 27:  # ESC
            break
        elif key == ord(' '):  # Space
            paused = not paused
        elif key >= ord('1') and key <= ord('5'):
            processing_mode = key - ord('0')
    
    cap.release()
    cv2.destroyAllWindows()

def ornek_2_frame_differencing():
    """
    Ã–rnek 2: Frame farkÄ± alma (Frame Differencing)
    """
    print("\nğŸ¯ Ã–rnek 2: Frame Differencing")
    print("=" * 35)
    
    # Webcam kullan (daha iyi sonuÃ§ iÃ§in)
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ Webcam aÃ§Ä±lamadÄ±!")
        return
    
    # Ä°lk frame'i al
    ret, previous_frame = cap.read()
    if not ret:
        print("âŒ Ä°lk frame alÄ±namadÄ±!")
        return
    
    previous_gray = cv2.cvtColor(previous_frame, cv2.COLOR_BGR2GRAY)
    
    print("ğŸ‘‹ KameranÄ±n Ã¶nÃ¼nde hareket edin!")
    print("ESC: Ã‡Ä±kÄ±ÅŸ, 't': Threshold ayarla")
    
    threshold_value = 30
    
    while True:
        ret, current_frame = cap.read()
        if not ret:
            break
        
        current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)
        
        # Frame farkÄ±nÄ± hesapla
        frame_diff = cv2.absdiff(previous_gray, current_gray)
        
        # Threshold uygula
        _, threshold_diff = cv2.threshold(frame_diff, threshold_value, 255, cv2.THRESH_BINARY)
        
        # Morfolojik iÅŸlemler (gÃ¼rÃ¼ltÃ¼ azaltma)
        kernel = np.ones((3, 3), np.uint8)
        threshold_diff = cv2.morphologyEx(threshold_diff, cv2.MORPH_OPENING, kernel)
        threshold_diff = cv2.morphologyEx(threshold_diff, cv2.MORPH_CLOSING, kernel)
        
        # Hareket alanÄ±nÄ± hesapla
        motion_area = cv2.countNonZero(threshold_diff)
        motion_percentage = (motion_area / (current_frame.shape[0] * current_frame.shape[1])) * 100
        
        # GÃ¶rselleÅŸtirme
        # Orijinal frame
        display_frame = current_frame.copy()
        cv2.putText(display_frame, f"Hareket: %{motion_percentage:.2f}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(display_frame, f"Threshold: {threshold_value}", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Frame diff'i renkli yap
        threshold_diff_colored = cv2.cvtColor(threshold_diff, cv2.COLOR_GRAY2BGR)
        
        # Yan yana gÃ¶ster
        combined = np.hstack((display_frame, threshold_diff_colored))
        cv2.imshow('Frame Differencing - Orijinal | Hareket', combined)
        
        # Ã–nceki frame'i gÃ¼ncelle
        previous_gray = current_gray.copy()
        
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break
        elif key == ord('t'):
            # Threshold ayarlama
            new_threshold = input(f"Yeni threshold deÄŸeri (mevcut: {threshold_value}): ")
            try:
                threshold_value = int(new_threshold)
                threshold_value = max(1, min(255, threshold_value))
            except:
                print("GeÃ§ersiz deÄŸer!")
    
    cap.release()
    cv2.destroyAllWindows()

def ornek_3_frame_blending():
    """
    Ã–rnek 3: Frame blending ve interpolation
    """
    print("\nğŸ¯ Ã–rnek 3: Frame Blending")
    print("=" * 30)
    
    # Test video
    video_path = "test_video.avi"
    if not os.path.exists(video_path):
        print("âŒ Test videosu bulunamadÄ±.")
        return
    
    cap = cv2.VideoCapture(video_path)
    processor = FrameProcessor(buffer_size=5)
    
    print("Blending modlarÄ±:")
    print("1: Normal")
    print("2: Ortalama blend (3 frame)")
    print("3: Hareket blur")
    print("4: Ghost effect")
    
    blend_mode = 1
    
    while True:
        ret, frame = cap.read()
        if not ret:
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue
        
        processor.add_frame(frame)
        
        if blend_mode == 1:
            # Normal frame
            result = frame.copy()
            mode_text = "Normal"
            
        elif blend_mode == 2 and len(processor.frame_buffer) >= 3:
            # Son 3 frame'in ortalamasÄ±
            frames = list(processor.frame_buffer)[-3:]
            result = np.zeros_like(frame, dtype=np.float32)
            for f in frames:
                result += f.astype(np.float32)
            result = (result / len(frames)).astype(np.uint8)
            mode_text = "Ortalama Blend"
            
        elif blend_mode == 3 and len(processor.frame_buffer) >= 2:
            # Hareket blur efekti
            current = processor.get_current_frame().astype(np.float32)
            previous = processor.get_previous_frame(1).astype(np.float32)
            # AÄŸÄ±rlÄ±klÄ± ortalama
            result = (0.7 * current + 0.3 * previous).astype(np.uint8)
            mode_text = "Hareket Blur"
            
        elif blend_mode == 4 and len(processor.frame_buffer) >= 3:
            # Ghost efekti - Ã¶nceki frame'leri ÅŸeffaf olarak bindirme
            result = processor.get_current_frame().copy().astype(np.float32)
            if len(processor.frame_buffer) >= 2:
                prev1 = processor.get_previous_frame(1).astype(np.float32)
                result = 0.8 * result + 0.2 * prev1
            if len(processor.frame_buffer) >= 3:
                prev2 = processor.get_previous_frame(2).astype(np.float32)
                result = 0.9 * result + 0.1 * prev2
            result = result.astype(np.uint8)
            mode_text = "Ghost Effect"
        else:
            result = frame.copy()
            mode_text = "Loading..."
        
        # Bilgi ekle
        cv2.putText(result, f"Mod: {mode_text}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(result, f"Buffer: {len(processor.frame_buffer)}/5", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        cv2.imshow('Frame Blending', result)
        
        key = cv2.waitKey(50) & 0xFF
        if key == 27:  # ESC
            break
        elif key >= ord('1') and key <= ord('4'):
            blend_mode = key - ord('0')
    
    cap.release()
    cv2.destroyAllWindows()

def ornek_4_frame_buffer_yonetimi():
    """
    Ã–rnek 4: Frame buffer yÃ¶netimi ve optimize iÅŸleme
    """
    print("\nğŸ¯ Ã–rnek 4: Frame Buffer YÃ¶netimi")
    print("=" * 40)
    
    class OptimizedFrameProcessor:
        def __init__(self, buffer_size=20):
            self.buffer = deque(maxlen=buffer_size)
            self.processed_cache = {}
            self.frame_index = 0
        
        def add_frame(self, frame):
            self.buffer.append({
                'frame': frame,
                'index': self.frame_index,
                'timestamp': time.time()
            })
            self.frame_index += 1
        
        def get_frame_stats(self):
            if not self.buffer:
                return {}
            
            # Buffer istatistikleri
            current_time = time.time()
            frame_times = [f['timestamp'] for f in self.buffer]
            
            if len(frame_times) > 1:
                fps = len(frame_times) / (max(frame_times) - min(frame_times))
                avg_interval = (max(frame_times) - min(frame_times)) / (len(frame_times) - 1)
            else:
                fps = 0
                avg_interval = 0
            
            return {
                'buffer_size': len(self.buffer),
                'max_buffer': self.buffer.maxlen,
                'fps': fps,
                'avg_interval': avg_interval,
                'cache_size': len(self.processed_cache)
            }
        
        def process_with_history(self, process_func, history_length=5):
            if len(self.buffer) < history_length:
                return None
            
            # Son N frame'i al
            recent_frames = [item['frame'] for item in list(self.buffer)[-history_length:]]
            return process_func(recent_frames)
    
    # Webcam ile test
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        # Webcam yoksa test video kullan
        cap = cv2.VideoCapture("test_video.avi")
    
    processor = OptimizedFrameProcessor(buffer_size=30)
    
    def temporal_average(frames):
        """Temporal averaging iÅŸlemi"""
        if not frames:
            return frames[0]
        
        result = np.zeros_like(frames[0], dtype=np.float32)
        for frame in frames:
            result += frame.astype(np.float32)
        return (result / len(frames)).astype(np.uint8)
    
    def motion_magnitude(frames):
        """Hareket bÃ¼yÃ¼klÃ¼ÄŸÃ¼ hesaplama"""
        if len(frames) < 2:
            return frames[0]
        
        # Son iki frame arasÄ±ndaki fark
        current = cv2.cvtColor(frames[-1], cv2.COLOR_BGR2GRAY)
        previous = cv2.cvtColor(frames[-2], cv2.COLOR_BGR2GRAY)
        
        diff = cv2.absdiff(current, previous)
        # FarkÄ± renkli gÃ¶ster
        diff_colored = cv2.applyColorMap(diff, cv2.COLORMAP_JET)
        return diff_colored
    
    process_mode = 1
    start_time = time.time()
    
    print("Ä°ÅŸleme modlarÄ±:")
    print("1: Normal")
    print("2: Temporal Average (5 frame)")
    print("3: Motion Magnitude")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            # Test video iÃ§in dÃ¶ngÃ¼
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue
        
        processor.add_frame(frame)
        
        # Ä°ÅŸleme moduna gÃ¶re frame iÅŸle
        if process_mode == 1:
            result = frame.copy()
        elif process_mode == 2:
            result = processor.process_with_history(temporal_average, 5)
            if result is None:
                result = frame.copy()
        elif process_mode == 3:
            result = processor.process_with_history(motion_magnitude, 2)
            if result is None:
                result = frame.copy()
        
        # Ä°statistikleri al
        stats = processor.get_frame_stats()
        
        # Bilgileri gÃ¶ster
        y_offset = 30
        cv2.putText(result, f"Mod: {process_mode}", (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        y_offset += 25
        cv2.putText(result, f"Buffer: {stats.get('buffer_size', 0)}/{stats.get('max_buffer', 0)}", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        y_offset += 25
        cv2.putText(result, f"FPS: {stats.get('fps', 0):.1f}", (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        y_offset += 25
        
        # Ã‡alÄ±ÅŸma sÃ¼resi
        elapsed = time.time() - start_time
        cv2.putText(result, f"SÃ¼re: {elapsed:.1f}s", (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        cv2.imshow('Frame Buffer YÃ¶netimi', result)
        
        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break
        elif key >= ord('1') and key <= ord('3'):
            process_mode = key - ord('0')
    
    cap.release()
    cv2.destroyAllWindows()

def ornek_5_threaded_processing():
    """
    Ã–rnek 5: Multi-threaded frame iÅŸleme
    """
    print("\nğŸ¯ Ã–rnek 5: Multi-threaded Ä°ÅŸleme")
    print("=" * 40)
    
    class ThreadedFrameProcessor:
        def __init__(self):
            self.input_queue = queue.Queue(maxsize=10)
            self.output_queue = queue.Queue(maxsize=10)
            self.running = False
            self.process_thread = None
            self.stats = {
                'processed_frames': 0,
                'processing_time': 0,
                'queue_full_count': 0
            }
        
        def start_processing(self):
            self.running = True
            self.process_thread = threading.Thread(target=self._process_worker)
            self.process_thread.start()
        
        def stop_processing(self):
            self.running = False
            if self.process_thread:
                self.process_thread.join()
        
        def add_frame(self, frame):
            try:
                self.input_queue.put(frame, block=False)
                return True
            except queue.Full:
                self.stats['queue_full_count'] += 1
                return False
        
        def get_processed_frame(self):
            try:
                return self.output_queue.get(block=False)
            except queue.Empty:
                return None
        
        def _process_worker(self):
            while self.running:
                try:
                    frame = self.input_queue.get(timeout=0.1)
                    
                    # Ä°ÅŸleme baÅŸlangÄ±cÄ±
                    start_time = time.time()
                    
                    # YoÄŸun iÅŸleme simÃ¼lasyonu - birden fazla filtre
                    processed = frame.copy()
                    
                    # 1. Gaussian blur
                    processed = cv2.GaussianBlur(processed, (5, 5), 0)
                    
                    # 2. Edge detection
                    gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)
                    edges = cv2.Canny(gray, 50, 150)
                    
                    # 3. Edge'leri orijinalle birleÅŸtir
                    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
                    processed = cv2.addWeighted(processed, 0.7, edges_colored, 0.3, 0)
                    
                    # Ä°ÅŸleme sÃ¼resi
                    process_time = time.time() - start_time
                    self.stats['processing_time'] += process_time
                    self.stats['processed_frames'] += 1
                    
                    # Ä°statistikleri frame'e ekle
                    avg_time = self.stats['processing_time'] / self.stats['processed_frames']
                    cv2.putText(processed, f"Avg Process: {avg_time*1000:.1f}ms", (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    cv2.putText(processed, f"Frames: {self.stats['processed_frames']}", (10, 55),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    cv2.putText(processed, f"Queue Full: {self.stats['queue_full_count']}", (10, 80),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    # Sonucu output queue'ya ekle
                    try:
                        self.output_queue.put(processed, block=False)
                    except queue.Full:
                        # Output queue dolu, eski frame'i at
                        try:
                            self.output_queue.get(block=False)
                            self.output_queue.put(processed, block=False)
                        except queue.Empty:
                            pass
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"Ä°ÅŸleme hatasÄ±: {e}")
    
    # Webcam ile test
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        cap = cv2.VideoCapture("test_video.avi")
    
    processor = ThreadedFrameProcessor()
    processor.start_processing()
    
    print("ğŸ“Š Threaded processing baÅŸlatÄ±ldÄ±")
    print("ESC: Ã‡Ä±kÄ±ÅŸ")
    
    last_fps_time = time.time()
    fps_counter = 0
    current_fps = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                # Video dÃ¶ngÃ¼sÃ¼
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
            
            # Frame'i iÅŸleme kuyruÄŸuna ekle
            frame_added = processor.add_frame(frame)
            
            # Ä°ÅŸlenmiÅŸ frame'i al
            processed_frame = processor.get_processed_frame()
            
            # GÃ¶sterilecek frame'i belirle
            if processed_frame is not None:
                display_frame = processed_frame
            else:
                display_frame = frame.copy()
                cv2.putText(display_frame, "Ä°ÅŸleniyor...", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # FPS hesaplama
            fps_counter += 1
            current_time = time.time()
            if current_time - last_fps_time >= 1.0:
                current_fps = fps_counter / (current_time - last_fps_time)
                fps_counter = 0
                last_fps_time = current_time
            
            # FPS bilgisini ekle
            cv2.putText(display_frame, f"FPS: {current_fps:.1f}", (10, display_frame.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Queue durumlarÄ±nÄ± gÃ¶ster
            input_size = processor.input_queue.qsize()
            output_size = processor.output_queue.qsize()
            cv2.putText(display_frame, f"Queue: {input_size}|{output_size}", (10, display_frame.shape[0] - 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            cv2.imshow('Threaded Processing', display_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
    
    finally:
        processor.stop_processing()
        cap.release()
        cv2.destroyAllWindows()
        
        print(f"\nğŸ“Š Ä°ÅŸleme Ä°statistikleri:")
        print(f"   Toplam iÅŸlenen frame: {processor.stats['processed_frames']}")
        print(f"   Ortalama iÅŸleme sÃ¼resi: {processor.stats['processing_time']/max(1, processor.stats['processed_frames'])*1000:.1f}ms")
        print(f"   Queue dolu sayÄ±sÄ±: {processor.stats['queue_full_count']}")

def demo_menu():
    """Demo menÃ¼sÃ¼"""
    while True:
        print("\n" + "="*50)
        print("ğŸ–¼ï¸ OpenCV Frame Ä°ÅŸleme Demo")
        print("="*50)
        print("1. ğŸï¸ Frame-by-Frame Ä°ÅŸleme")
        print("2. ğŸ“Š Frame Differencing")
        print("3. ğŸŒˆ Frame Blending & Interpolation")
        print("4. ğŸ’¾ Frame Buffer YÃ¶netimi")
        print("5. âš¡ Multi-threaded Ä°ÅŸleme")
        print("0. âŒ Ã‡Ä±kÄ±ÅŸ")
        
        try:
            secim = input("\nSeÃ§iminizi yapÄ±n (0-5): ").strip()
            
            if secim == "0":
                print("ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
                break
            elif secim == "1":
                ornek_1_frame_by_frame_islreme()
            elif secim == "2":
                ornek_2_frame_differencing()
            elif secim == "3":
                ornek_3_frame_blending()
            elif secim == "4":  
                ornek_4_frame_buffer_yonetimi()
            elif secim == "5":
                ornek_5_threaded_processing()
            else:
                print("âŒ GeÃ§ersiz seÃ§im! LÃ¼tfen 0-5 arasÄ±nda bir sayÄ± girin.")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Program sonlandÄ±rÄ±ldÄ±.")
            break
        except Exception as e:
            print(f"âŒ Hata oluÅŸtu: {e}")

def main():
    """Ana fonksiyon"""
    print("ğŸ–¼ï¸ OpenCV Frame Ä°ÅŸleme")
    print("Bu modÃ¼l frame-by-frame video iÅŸleme tekniklerini Ã¶ÄŸretir.")
    print("\nğŸ’¡ Gereksinimler:")
    print("   - OpenCV (pip install opencv-python)")
    print("   - NumPy (pip install numpy)")
    print("   - Threading (built-in)")
    print("   - Webcam (bazÄ± Ã¶rnekler iÃ§in)")
    
    demo_menu()

if __name__ == "__main__":
    main()

# ğŸ“ NOTLAR:
# 1. Frame buffer boyutu RAM kullanÄ±mÄ±nÄ± etkiler
# 2. Multi-threading performansÄ± artÄ±rabilir
# 3. Queue boyutlarÄ± sistemin hÄ±zÄ±na gÃ¶re ayarlayÄ±n
# 4. Frame differencing hareket algÄ±lama iÃ§in temeldir
# 5. Blending efektleri yaratÄ±cÄ± video dÃ¼zenleme iÃ§in kullanÄ±ÅŸlÄ±dÄ±r